% Solve a Pattern Recognition Problem with a Neural Network
% Script generated by Neural Pattern Recognition app
% Created 25-Mar-2018 14:01:49
%
% This script assumes these variables are defined:
%
%   z - input data.
%   dummy - target data.
X = load('mdc-gender-selected-features'); % ucitavanje podataka
    % X je struktura koja ima data (78x41) i features u kome se nalaze nazivi
    % obelezja
    podaci = X.data(:,1:end-1);  
    labele=logical((X.data(:,end))-1);
    lab=(X.data(:,end));
    dummy= dummyvar(lab);
    obelezja=X.features; % nazivi obelezja
    z= podaci; % 
x = z';
t = dummy';
K= lab;
% Choose a Training Function
% For a list of all training functions type: help nntrain
% 'trainlm' is usually fastest.
% 'trainbr' takes longer but may be better for challenging problems.
% 'trainscg' uses less memory. Suitable in low memory situations.
trainFcn = 'trainscg';  % Scaled conjugate gradient backpropagation.

% Create a Pattern Recognition Network
num_layers=3;
hiddenLayerSize = 64;
%net = patternnet(ones(1,num_layers)*hiddenLayerSize);
net = patternnet([64 64 64]);
net.trainParam.max_fail= 20;
for i = 1:num_layers
    net.layers{i}.transferFcn='satlins';
end
% Choose Input and Output Pre/Post-Processing Functions
% For a list of all processing functions type: help nnprocess
net.input.processFcns = {'removeconstantrows','mapminmax'};
net.output.processFcns = {'removeconstantrows','mapminmax'};

rng(1);

greske_trng=[];
tacnost_trng=[];
greske_val=[];
tacnost_val=[];
greske_test=[];
tacnost_test=[];
mat_konf = zeros(2);

cv=cvpartition(K,'HoldOut',0.15);
trng_skup = x(:,cv.training);
test_skup = x(:,cv.test);
trng_lab = K(cv.training);
test_lab = K(cv.test);
trng_lab_dummy = t(:,cv.training);
test_lab_dummy = t(:,cv.test);
brk=5;

c=cvpartition(trng_lab,'KFold',brk);
for i=1:brk
    % Setup Division of Data for Training, Validation, Testing
    % For a list of all data division functions type: help nndivide
    net.divideFcn = 'divideind';  % Divide data randomly
% % %     prvi=c.TrainSize(i); % 692 691 691 ... 692
% % %     drugi=c.TestSize(i); % 76 77 77 ... 76
% % %     net.divideFcn='divideind';
% % %     pos=length(K);
    ind_trng = c.training(i).*[1:length(c.training(i))]';
    ind_trng = ind_trng(ind_trng~=0);
    net.divideParam.trainInd = ind_trng;
    ind_val = c.test(i).*[1:length(c.test(i))]';
    ind_val = ind_val(ind_val~=0);
    %net.divideParam.testInd = ind_test(1:floor(numel(ind_test)/2));
    %net.divideParam.valInd = ind_test(floor(numel(ind_test)/2):numel(ind_test));
    
    net.divideParam.testInd = [];
    net.divideParam.valInd = ind_val;
    
    net.plotFcns = {'plotperform','plottrainstate','ploterrhist', ...
        'plotconfusion', 'plotroc'};
    net.trainParam.epochs = 100;
    net.trainParam.lr = 0.001;
    % Train the Network
    [trained_net,tr] = train(net,trng_skup,trng_lab_dummy);

    models = net;
    trng_rec = tr;
    % Error on test set
    y = trained_net(trng_skup(:,ind_val)); %PREDVIDJANJE KLASE val UZORAKA
    e = gsubtract(trng_lab_dummy(:,ind_val),y);
    %performance = perform(net,t,y);
    tind = vec2ind(trng_lab_dummy(:,ind_val));
    yind = vec2ind(y);
    percentErrors = sum(tind ~= yind)/numel(tind);
    greske_val=[greske_val percentErrors];
    percentAccuracy=1-percentErrors;
    tacnost_val=[tacnost_val percentAccuracy]; %TACNOST NA val SKUPU
    
    % Error on trng set
    y = trained_net(trng_skup(:,ind_trng)); %PREDVIDJANJE KLASE TRNG UZORAKA
    e = gsubtract(trng_lab_dummy(:,ind_trng),y);
    %performance = perform(net,t,y);
    tind = vec2ind(trng_lab_dummy(:,ind_trng));
    yind = vec2ind(y);
    percentErrors = sum(tind ~= yind)/numel(tind);
    greske_trng=[greske_trng percentErrors];
    percentAccuracy=1-percentErrors;
    tacnost_trng=[tacnost_trng percentAccuracy]; %TACNOST NA TRNG SKUPU

    y = trained_net(test_skup); %PREDVIDJANJE KLASE test UZORAKA
    e = gsubtract(test_lab_dummy,y);
    %performance = perform(net,t,y);
    tind = vec2ind(test_lab_dummy);
    yind = vec2ind(y);
    percentErrors = sum(tind ~= yind)/numel(tind);
    greske_test=[greske_test percentErrors];
    percentAccuracy=1-percentErrors;
    tacnost_test=[tacnost_test percentAccuracy]; %TACNOST NA test SKUPU
    mat_konf=mat_konf+confusionmat(test_lab,yind');
end

greske_mean_trng=mean(greske_trng);
tacnost_mean_trng=mean(tacnost_trng);
greske_mean_val=mean(greske_val);
tacnost_mean_val=mean(tacnost_val);
greske_mean_test=mean(greske_test);
tacnost_mean_test=mean(tacnost_test);
[T,P,O,F,FPR]=mere(mat_konf);
 
Q= table(T,P,O,F,'RowNames',{'Neural'},'VariableNames',{'Tacnost', 'Preciznost', 'Odziv','F_mera'})


% View the Network
view(trained_net)

% Plots
% Uncomment these lines to enable various plots.
%figure, plotperform(tr)
%figure, plottrainstate(tr)
%figure, ploterrhist(e)
%figure, plotconfusion(t,y)
%figure, plotroc(t,y)

% % Deployment
% % Change the (false) values to (true) to enable the following code blocks.
% % See the help for each generation function for more information.
if (false)
    % Generate MATLAB function for neural network for application
    % deployment in MATLAB scripts or with MATLAB Compiler and Builder
    % tools, or simply to examine the calculations your trained neural
    % network performs.
    genFunction(net,'myNeuralNetworkFunction');
    y = myNeuralNetworkFunction(x);
end
if (false)
    % Generate a matrix-only MATLAB function for neural network code
    % generation with MATLAB Coder tools.
    genFunction(net,'myNeuralNetworkFunction','MatrixOnly','yes');
    y = myNeuralNetworkFunction(x);
end
if (false)
    % Generate a Simulink diagram for simulation or deployment with.
    % Simulink Coder tools.
    gensim(net);
end
